{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1=\"cricket is one of the popular game\"\n",
    "doc2=\"ms dhoni is cricket player\"\n",
    "doc3=\"football is another popular game\"\n",
    "doc4=\"i love cricket game\"\n",
    "doc5=\"i love both cricket and football\"\n",
    "doc6=\"football is best game\"\n",
    "doc7=\"odi and twenty is best cricket format\"\n",
    "doc8=\"messi is best football player\"\n",
    "doc9=\"ronaldo and messi are footballer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list=['i','is','the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cricket', 'is', 'one', 'of', 'the', 'popular245#', 'game']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenizer Function\n",
    "def Tokenizer(text):\n",
    "    text=text.split()\n",
    "    return text\n",
    "tokenized_doc1=Tokenizer(doc1)\n",
    "tokenized_doc2=Tokenizer(doc2)\n",
    "tokenized_doc3=Tokenizer(doc3)\n",
    "tokenized_doc4=Tokenizer(doc4)\n",
    "tokenized_doc5=Tokenizer(doc5)\n",
    "tokenized_doc6=Tokenizer(doc6)\n",
    "tokenized_doc7=Tokenizer(doc7)\n",
    "tokenized_doc8=Tokenizer(doc8)\n",
    "tokenized_doc9=Tokenizer(doc9)\n",
    "tokenized_doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Stop Words\n",
    "def Remove_stopword(text):\n",
    "    remove_stop=\" \"\n",
    "    list1=[]\n",
    "    for i in text:\n",
    "        if i not in stopword_list:\n",
    "            list1.append(i)\n",
    "    return remove_stop.join(list1)\n",
    "preprocess_doc1=Remove_stopword(tokenized_doc1)\n",
    "preprocess_doc2=Remove_stopword(tokenized_doc2)\n",
    "preprocess_doc3=Remove_stopword(tokenized_doc3)\n",
    "preprocess_doc4=Remove_stopword(tokenized_doc4)\n",
    "preprocess_doc5=Remove_stopword(tokenized_doc5)\n",
    "preprocess_doc6=Remove_stopword(tokenized_doc6)\n",
    "preprocess_doc7=Remove_stopword(tokenized_doc7)\n",
    "preprocess_doc8=Remove_stopword(tokenized_doc8)\n",
    "preprocess_doc9=Remove_stopword(tokenized_doc9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cricket one of popular game ms dhoni cricket player football another popular game love cricket game love both cricket and football football best game odi and twenty best cricket format messi best football player ronaldo and messi are footballer'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_doc=preprocess_doc1+\" \"+preprocess_doc2+\" \"+preprocess_doc3+\" \"+preprocess_doc4+\" \"+preprocess_doc5+\" \"+preprocess_doc6+\" \"+preprocess_doc7+\" \"+preprocess_doc8+\" \"+preprocess_doc9\n",
    "vocab_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and',\n",
       " 'another',\n",
       " 'are',\n",
       " 'best',\n",
       " 'both',\n",
       " 'cricket',\n",
       " 'dhoni',\n",
       " 'football',\n",
       " 'footballer',\n",
       " 'format',\n",
       " 'game',\n",
       " 'love',\n",
       " 'messi',\n",
       " 'ms',\n",
       " 'odi',\n",
       " 'of',\n",
       " 'one',\n",
       " 'player',\n",
       " 'popular',\n",
       " 'ronaldo',\n",
       " 'twenty'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_vocab(doc):\n",
    "    doc=vocab_doc.split()\n",
    "    return(set(doc))\n",
    "vocabs=get_vocab(vocab_doc)\n",
    "\n",
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-fd1a7bc353e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvocab\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'vocab' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and': 20,\n",
       " 'another': 1,\n",
       " 'are': 3,\n",
       " 'best': 16,\n",
       " 'both': 7,\n",
       " 'cricket': 13,\n",
       " 'dhoni': 12,\n",
       " 'football': 14,\n",
       " 'footballer': 11,\n",
       " 'format': 10,\n",
       " 'game': 15,\n",
       " 'love': 8,\n",
       " 'messi': 19,\n",
       " 'ms': 6,\n",
       " 'odi': 17,\n",
       " 'of': 9,\n",
       " 'one': 4,\n",
       " 'player': 21,\n",
       " 'popular': 18,\n",
       " 'ronaldo': 2,\n",
       " 'twenty': 5}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_vocab_to_id(vocab):\n",
    "    res={}\n",
    "    for i,token in enumerate(vocab):\n",
    "        res[token]=i+1\n",
    "    return res\n",
    "vocab_with_id=map_vocab_to_id(vocabs)\n",
    "vocab_with_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cricket', 'one', 'of', 'popular', 'game']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 Ngram and Feature Vectors Count(tf) count\n",
    "def generate_ngrams(s, n=1):\n",
    "    tokens = [token for token in s.split(\" \") if token != \"\"]\n",
    "    \n",
    "    ngrams = zip(*[tokens[i:] for i in range(n)])\n",
    "    return [\" \".join(ngram) for ngram in ngrams]\n",
    "ngram_doc1=generate_ngrams(preprocess_doc1)\n",
    "ngram_doc2=generate_ngrams(preprocess_doc2)\n",
    "ngram_doc3=generate_ngrams(preprocess_doc3)\n",
    "ngram_doc4=generate_ngrams(preprocess_doc4)\n",
    "ngram_doc5=generate_ngrams(preprocess_doc5)\n",
    "ngram_doc6=generate_ngrams(preprocess_doc6)\n",
    "ngram_doc7=generate_ngrams(preprocess_doc7)\n",
    "ngram_doc8=generate_ngrams(preprocess_doc8)\n",
    "ngram_doc9=generate_ngrams(preprocess_doc9)\n",
    "\n",
    "ngram_doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and': 0,\n",
       " 'another': 0,\n",
       " 'are': 0,\n",
       " 'best': 0,\n",
       " 'both': 0,\n",
       " 'cricket': 1,\n",
       " 'dhoni': 0,\n",
       " 'football': 0,\n",
       " 'footballer': 0,\n",
       " 'format': 0,\n",
       " 'game': 1,\n",
       " 'love': 0,\n",
       " 'messi': 0,\n",
       " 'ms': 0,\n",
       " 'odi': 0,\n",
       " 'of': 1,\n",
       " 'one': 1,\n",
       " 'player': 0,\n",
       " 'popular': 1,\n",
       " 'ronaldo': 0,\n",
       " 'twenty': 0}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_word(vocab,ngram_doc):\n",
    "    numOfWords = dict.fromkeys(vocab, 0)\n",
    "    #print(numOfWords)\n",
    "    for word in ngram_doc:\n",
    "        \n",
    "        numOfWords[word] += 1\n",
    "    return numOfWords    \n",
    "numOfWords1=count_word(vocabs,ngram_doc1)\n",
    "numOfWords2=count_word(vocabs,ngram_doc2)\n",
    "numOfWords3=count_word(vocabs,ngram_doc3)\n",
    "numOfWords4=count_word(vocabs,ngram_doc4)\n",
    "numOfWords5=count_word(vocabs,ngram_doc5)\n",
    "numOfWords6=count_word(vocabs,ngram_doc6)\n",
    "numOfWords7=count_word(vocabs,ngram_doc7)\n",
    "numOfWords8=count_word(vocabs,ngram_doc8)\n",
    "numOfWords9=count_word(vocabs,ngram_doc9)  \n",
    "numOfWords1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "another 0\n",
      "ronaldo 0\n",
      "are 0\n",
      "one 1\n",
      "twenty 0\n",
      "ms 0\n",
      "both 0\n",
      "love 0\n",
      "of 1\n",
      "format 0\n",
      "footballer 0\n",
      "dhoni 0\n",
      "cricket 1\n",
      "football 0\n",
      "game 1\n",
      "best 0\n",
      "odi 0\n",
      "popular 1\n",
      "messi 0\n",
      "and 0\n",
      "player 0\n",
      "another 0\n",
      "ronaldo 0\n",
      "are 0\n",
      "one 0\n",
      "twenty 0\n",
      "ms 1\n",
      "both 0\n",
      "love 0\n",
      "of 0\n",
      "format 0\n",
      "footballer 0\n",
      "dhoni 1\n",
      "cricket 1\n",
      "football 0\n",
      "game 0\n",
      "best 0\n",
      "odi 0\n",
      "popular 0\n",
      "messi 0\n",
      "and 0\n",
      "player 1\n",
      "another 1\n",
      "ronaldo 0\n",
      "are 0\n",
      "one 0\n",
      "twenty 0\n",
      "ms 0\n",
      "both 0\n",
      "love 0\n",
      "of 0\n",
      "format 0\n",
      "footballer 0\n",
      "dhoni 0\n",
      "cricket 0\n",
      "football 1\n",
      "game 1\n",
      "best 0\n",
      "odi 0\n",
      "popular 1\n",
      "messi 0\n",
      "and 0\n",
      "player 0\n",
      "another 0\n",
      "ronaldo 0\n",
      "are 0\n",
      "one 0\n",
      "twenty 0\n",
      "ms 0\n",
      "both 0\n",
      "love 1\n",
      "of 0\n",
      "format 0\n",
      "footballer 0\n",
      "dhoni 0\n",
      "cricket 1\n",
      "football 0\n",
      "game 1\n",
      "best 0\n",
      "odi 0\n",
      "popular 0\n",
      "messi 0\n",
      "and 0\n",
      "player 0\n",
      "another 0\n",
      "ronaldo 0\n",
      "are 0\n",
      "one 0\n",
      "twenty 0\n",
      "ms 0\n",
      "both 1\n",
      "love 1\n",
      "of 0\n",
      "format 0\n",
      "footballer 0\n",
      "dhoni 0\n",
      "cricket 1\n",
      "football 1\n",
      "game 0\n",
      "best 0\n",
      "odi 0\n",
      "popular 0\n",
      "messi 0\n",
      "and 1\n",
      "player 0\n",
      "another 0\n",
      "ronaldo 0\n",
      "are 0\n",
      "one 0\n",
      "twenty 0\n",
      "ms 0\n",
      "both 0\n",
      "love 0\n",
      "of 0\n",
      "format 0\n",
      "footballer 0\n",
      "dhoni 0\n",
      "cricket 0\n",
      "football 1\n",
      "game 1\n",
      "best 1\n",
      "odi 0\n",
      "popular 0\n",
      "messi 0\n",
      "and 0\n",
      "player 0\n",
      "another 0\n",
      "ronaldo 0\n",
      "are 0\n",
      "one 0\n",
      "twenty 1\n",
      "ms 0\n",
      "both 0\n",
      "love 0\n",
      "of 0\n",
      "format 1\n",
      "footballer 0\n",
      "dhoni 0\n",
      "cricket 1\n",
      "football 0\n",
      "game 0\n",
      "best 1\n",
      "odi 1\n",
      "popular 0\n",
      "messi 0\n",
      "and 1\n",
      "player 0\n",
      "another 0\n",
      "ronaldo 0\n",
      "are 0\n",
      "one 0\n",
      "twenty 0\n",
      "ms 0\n",
      "both 0\n",
      "love 0\n",
      "of 0\n",
      "format 0\n",
      "footballer 0\n",
      "dhoni 0\n",
      "cricket 0\n",
      "football 1\n",
      "game 0\n",
      "best 1\n",
      "odi 0\n",
      "popular 0\n",
      "messi 1\n",
      "and 0\n",
      "player 1\n",
      "another 0\n",
      "ronaldo 1\n",
      "are 1\n",
      "one 0\n",
      "twenty 0\n",
      "ms 0\n",
      "both 0\n",
      "love 0\n",
      "of 0\n",
      "format 0\n",
      "footballer 1\n",
      "dhoni 0\n",
      "cricket 0\n",
      "football 0\n",
      "game 0\n",
      "best 0\n",
      "odi 0\n",
      "popular 0\n",
      "messi 1\n",
      "and 1\n",
      "player 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'and': 0.0,\n",
       " 'another': 0.0,\n",
       " 'are': 0.0,\n",
       " 'best': 0.0,\n",
       " 'both': 0.0,\n",
       " 'cricket': 0.14285714285714285,\n",
       " 'dhoni': 0.0,\n",
       " 'football': 0.0,\n",
       " 'footballer': 0.0,\n",
       " 'format': 0.0,\n",
       " 'game': 0.14285714285714285,\n",
       " 'love': 0.0,\n",
       " 'messi': 0.0,\n",
       " 'ms': 0.0,\n",
       " 'odi': 0.0,\n",
       " 'of': 0.14285714285714285,\n",
       " 'one': 0.14285714285714285,\n",
       " 'player': 0.0,\n",
       " 'popular': 0.14285714285714285,\n",
       " 'ronaldo': 0.0,\n",
       " 'twenty': 0.0}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df\n",
    "def computeTF(wordDict, bagOfWords):\n",
    "    tfDict = {}\n",
    "    bagOfWordsCount = len(bagOfWords)\n",
    "    for word, count in wordDict.items():\n",
    "#         print(word,count)\n",
    "        tfDict[word] = count / float(bagOfWordsCount)\n",
    "    return tfDict\n",
    "tf1=computeTF(numOfWords1,tokenized_doc1)\n",
    "tf2=computeTF(numOfWords2,tokenized_doc2)\n",
    "tf3=computeTF(numOfWords3,tokenized_doc3)\n",
    "tf4=computeTF(numOfWords4,tokenized_doc4)\n",
    "tf5=computeTF(numOfWords5,tokenized_doc5)\n",
    "tf6=computeTF(numOfWords6,tokenized_doc6)\n",
    "tf7=computeTF(numOfWords7,tokenized_doc7)\n",
    "tf8=computeTF(numOfWords8,tokenized_doc8)\n",
    "tf9=computeTF(numOfWords9,tokenized_doc9)\n",
    "tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and': 2.09861228866811,\n",
       " 'another': 3.1972245773362196,\n",
       " 'are': 3.1972245773362196,\n",
       " 'best': 2.09861228866811,\n",
       " 'both': 3.1972245773362196,\n",
       " 'cricket': 1.587786664902119,\n",
       " 'dhoni': 3.1972245773362196,\n",
       " 'football': 1.8109302162163288,\n",
       " 'footballer': 3.1972245773362196,\n",
       " 'format': 3.1972245773362196,\n",
       " 'game': 1.8109302162163288,\n",
       " 'love': 2.504077396776274,\n",
       " 'messi': 2.504077396776274,\n",
       " 'ms': 3.1972245773362196,\n",
       " 'odi': 3.1972245773362196,\n",
       " 'of': 3.1972245773362196,\n",
       " 'one': 3.1972245773362196,\n",
       " 'player': 2.504077396776274,\n",
       " 'popular': 2.504077396776274,\n",
       " 'ronaldo': 3.1972245773362196,\n",
       " 'twenty': 3.1972245773362196}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def computeIDF(documents):\n",
    "    import math\n",
    "    N = len(documents)\n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    \n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "           \n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "                \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N /float(val))+1\n",
    "    return idfDict\n",
    "idfs = computeIDF([numOfWords1,numOfWords2,numOfWords3,numOfWords4,numOfWords5,numOfWords6,numOfWords7,numOfWords8,numOfWords9])\n",
    "idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>another</th>\n",
       "      <th>are</th>\n",
       "      <th>best</th>\n",
       "      <th>both</th>\n",
       "      <th>cricket</th>\n",
       "      <th>dhoni</th>\n",
       "      <th>football</th>\n",
       "      <th>footballer</th>\n",
       "      <th>format</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>messi</th>\n",
       "      <th>ms</th>\n",
       "      <th>odi</th>\n",
       "      <th>of</th>\n",
       "      <th>one</th>\n",
       "      <th>player</th>\n",
       "      <th>popular</th>\n",
       "      <th>ronaldo</th>\n",
       "      <th>twenty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.456746</td>\n",
       "      <td>0.456746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317557</td>\n",
       "      <td>0.639445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.362186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.349769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.532871</td>\n",
       "      <td>0.264631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.524653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.299802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.299802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.456746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.456746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.456746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.419722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.362186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.419722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639445</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        and   another       are      best      both   cricket     dhoni  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.226827  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.317557  0.639445   \n",
       "2  0.000000  0.639445  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.396947  0.000000   \n",
       "4  0.349769  0.000000  0.000000  0.000000  0.532871  0.264631  0.000000   \n",
       "5  0.000000  0.000000  0.000000  0.524653  0.000000  0.000000  0.000000   \n",
       "6  0.299802  0.000000  0.000000  0.299802  0.000000  0.226827  0.000000   \n",
       "7  0.000000  0.000000  0.000000  0.419722  0.000000  0.000000  0.000000   \n",
       "8  0.419722  0.000000  0.639445  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "   football  footballer    format    ...         love     messi        ms  \\\n",
       "0  0.000000    0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "1  0.000000    0.000000  0.000000    ...     0.000000  0.000000  0.639445   \n",
       "2  0.362186    0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "3  0.000000    0.000000  0.000000    ...     0.626019  0.000000  0.000000   \n",
       "4  0.301822    0.000000  0.000000    ...     0.417346  0.000000  0.000000   \n",
       "5  0.452733    0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "6  0.000000    0.000000  0.456746    ...     0.000000  0.000000  0.000000   \n",
       "7  0.362186    0.000000  0.000000    ...     0.000000  0.500815  0.000000   \n",
       "8  0.000000    0.639445  0.000000    ...     0.000000  0.500815  0.000000   \n",
       "\n",
       "        odi        of       one    player   popular   ronaldo    twenty  \n",
       "0  0.000000  0.456746  0.456746  0.000000  0.357725  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.500815  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.500815  0.000000  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "5  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "6  0.456746  0.000000  0.000000  0.000000  0.000000  0.000000  0.456746  \n",
       "7  0.000000  0.000000  0.000000  0.500815  0.000000  0.000000  0.000000  \n",
       "8  0.000000  0.000000  0.000000  0.000000  0.000000  0.639445  0.000000  \n",
       "\n",
       "[9 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf*idf\n",
    "def computeTFIDF(tfBagOfWords, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBagOfWords.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf\n",
    "tfidf1 = computeTFIDF(tf1, idfs)\n",
    "tfidf2 = computeTFIDF(tf2, idfs)\n",
    "tfidf3 = computeTFIDF(tf3, idfs)\n",
    "tfidf4 = computeTFIDF(tf4, idfs)\n",
    "tfidf5 = computeTFIDF(tf5, idfs)\n",
    "tfidf6 = computeTFIDF(tf6, idfs)\n",
    "tfidf7 = computeTFIDF(tf7, idfs)\n",
    "tfidf8 = computeTFIDF(tf8, idfs)\n",
    "tfidf9 = computeTFIDF(tf9, idfs)\n",
    "\n",
    "df = pd.DataFrame([tfidf1, tfidf2,tfidf3,tfidf4,tfidf5,tfidf6,tfidf7,tfidf8,tfidf9])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering\n",
    "category=['cricket','cricket','football','cricket','cricket','football','cricket','football','football']\n",
    "document=['doc1','doc2','doc3','doc4','doc5','doc6','doc7','doc8','doc9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 2, 1, 7, 0, 1, 2, 0, 0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist =1-cosine_similarity(df)\n",
    "abc=[]\n",
    "for i in dist:\n",
    "    abc.append(i.argmax())\n",
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cricket': 2, 'football': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(category,abc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cricket': 'doc7', 'football': 'doc9'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(category,document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  encode_text(test_text,vocab_with_id):\n",
    "    tokens=test_text.split()\n",
    "    res=list(vocab_with_id.keys())\n",
    "    for i, token in enumerate(res):\n",
    "        if token in tokens:\n",
    "            res[i]=vocab_with_id[token]\n",
    "        else:\n",
    "            res[i]=0\n",
    "    return res \n",
    "\n",
    "v1=encode_text(doc1,vocab_with_id)\n",
    "v2=encode_text(doc2,vocab_with_id)\n",
    "v3=encode_text(doc3,vocab_with_id)\n",
    "v4=encode_text(doc4,vocab_with_id)\n",
    "v5=encode_text(doc5,vocab_with_id)\n",
    "v6=encode_text(doc6,vocab_with_id)\n",
    "v7=encode_text(doc7,vocab_with_id)\n",
    "v8=encode_text(doc9,vocab_with_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compute_cosine_similarity(v1,v2):\n",
    "    mag1=np.linalg.norm(v1)\n",
    "    mag2=np.linalg.norm(v2)\n",
    "    return np.dot(v1,v2)/(mag1*mag2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2106174520614017"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Compute_cosine_similarity(v1,v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1=\"cricket is one of the popular245# game\"\n",
    "doc2=\"ms dhoni is cricket player\"\n",
    "doc3=\"football*%3 is another popular game\"\n",
    "doc4=\"i love cricket game\"\n",
    "doc5=\"i love both cricket and football\"\n",
    "doc6=\"football is best game\"\n",
    "doc7=\"odi and twenty is best cricket format\"\n",
    "doc8=\"messi is best football player\"\n",
    "doc9=\"ronaldo and messi are footballer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Oriented technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cricket is one of the popular245# game',\n",
       " 'ms dhoni is cricket player',\n",
       " 'football*%3 is another popular game',\n",
       " 'i love cricket game',\n",
       " 'i love both cricket and football',\n",
       " 'football is best game',\n",
       " 'odi and twenty is best cricket format',\n",
       " 'messi is best football player',\n",
       " 'ronaldo and messi are footballer']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#class preprocessor\n",
    "#preprocess=get_preprocess(document,stopwords_list,tokenization_pattern=\"\")\n",
    "# tf_idf=get_feature_vector(processed,ngram)\n",
    "# class clustering\n",
    "# cluster=get_cluster(tf_idf,number_cluster)\n",
    "doc=[doc1,doc2,doc3,doc4,doc5,doc6,doc7,doc8,doc9]\n",
    "target=[1,1,0,1,0,1,1,0,0]\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-5357383a306f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrandom\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from random import randrange\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess:\n",
    "    def Remove_re(self,text):\n",
    "        global N\n",
    "        N=len(text)\n",
    "        data=[]\n",
    "        for i in range(N):\n",
    "            data1=re.sub(\"[^a-zA-Z]+\",' ',text[i])\n",
    "            data.append(data1)\n",
    "        return data\n",
    "    def Tokenized(self, text):\n",
    "        message=obj1.Remove_re(self.text)\n",
    "        new_list=[]\n",
    "        for i in message:\n",
    "            split_text=i.split()\n",
    "            new_list.append(split_text)\n",
    "        return new_list\n",
    "        \n",
    "    def Remove_Stop(self,text):\n",
    "        stopword_list=['i','is','of']\n",
    "        self.text=text\n",
    "        result=obj1.Tokenized(text)\n",
    "        new_list=[]\n",
    "        for i in result:\n",
    "            a=[a for a  in i if a not in stopword_list]\n",
    "            new_list.append(a)\n",
    "        return new_list\n",
    "    def Vocabs(self,text):\n",
    "        self.text=text\n",
    "        data=obj1.Remove_Stop(text)\n",
    "        new_data=[]\n",
    "        for i in data:\n",
    "            for j in i:\n",
    "                new_data.append(j)\n",
    "        return(set(new_data))\n",
    "    def map_vocab_to_id(self,text):\n",
    "        self.text=text\n",
    "        res={}\n",
    "        for i,token in enumerate(obj1.Vocabs(self.text)):\n",
    "            res[token]=i+1\n",
    "        return res\n",
    "    \n",
    "    def get_preprocess(self,text):\n",
    "        self.text=text\n",
    "        data=obj1.Remove_Stop(text)\n",
    "        a=[\" \".join(a) for a  in data]\n",
    "        return a\n",
    "    def generate_ngrams(self,s, n=1):\n",
    "        global M\n",
    "        N=len(s)\n",
    "        self.s=s\n",
    "        s=obj1.get_preprocess(s)\n",
    "        l=[]\n",
    "        for a in range(N):\n",
    "            tokens = [token for token in s[a].split(\" \") if token != \"\"]\n",
    "            ngrams = zip(*[tokens[i:] for i in range(n)])\n",
    "            a=[\" \".join(ngram) for ngram in ngrams]\n",
    "            l.append(a)\n",
    "        return l\n",
    "    def count_word(self,text):\n",
    "        vocab=obj1.Vocabs(self.text)\n",
    "        ngram_doc=obj1.generate_ngrams(self.text)\n",
    "        numOfWords = dict.fromkeys(vocab, 0)\n",
    "        word_count=[]\n",
    "        for i in range(N):\n",
    "            for word in ngram_doc[i]:\n",
    "                numOfWords[word] += 1\n",
    "            word_count.append(numOfWords)\n",
    "            numOfWords = dict.fromkeys(vocab, 0)\n",
    "            \n",
    "        return word_count\n",
    "    \n",
    "    def ComputeTF(self,text):\n",
    "        self.text=text\n",
    "        wordDict=obj1.count_word(text)\n",
    "        bagofword=obj1.Tokenized(text)\n",
    "        counts=[]\n",
    "        for i in range(N):\n",
    "            bagofwordcount=len(bagofword[i])\n",
    "            counts.append(bagofwordcount)\n",
    "        tfDict = {}\n",
    "        tf=[]\n",
    "        for i in range(N):\n",
    "            for word, count in wordDict[i].items():\n",
    "                tfDict[word] = count / counts[i]\n",
    "        \n",
    "            tf.append(tfDict)\n",
    "            tfDict={}\n",
    "        return tf\n",
    "    def computeIDF(self, text):\n",
    "        documents=obj1.count_word(text)\n",
    "        import math\n",
    "        N = len(documents)\n",
    "        idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "\n",
    "        for document in documents:\n",
    "            for word, val in document.items():\n",
    "\n",
    "                if val > 0:\n",
    "                    idfDict[word] += 1\n",
    "\n",
    "        for word, val in idfDict.items():\n",
    "            idfDict[word] = math.log(N /float(val))+1\n",
    "        return idfDict\n",
    "    \n",
    "    def computeTFIDF(self,text):\n",
    "        tfBagOfWords=obj1.ComputeTF(self.text)\n",
    "        idf=obj1.computeIDF(self.text)\n",
    "       \n",
    "        tfidf = {}\n",
    "        TFIDF=[]\n",
    "        for i in range(N):\n",
    "            for word, val in tfBagOfWords[i].items():\n",
    "                tfidf[word] = val * idf[word]\n",
    "                tfidf=tfidf\n",
    "            TFIDF.append(tfidf)\n",
    "            tfidf={}\n",
    "\n",
    "        return TFIDF\n",
    "    \n",
    "\n",
    "\n",
    "obj1=Preprocess()\n",
    "obj1.Vocabs(doc)\n",
    "tf = obj1.ComputeTF(doc)\n",
    "preprocess_data=obj1.computeTFIDF(doc)\n",
    "data=pd.DataFrame(preprocess_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSplit:\n",
    "    def train_test_split(self,dataset,target, split):\n",
    "        train_x = list()\n",
    "        train_y=list()\n",
    "        train_size = split * len(dataset)\n",
    "        test_x = list(dataset)\n",
    "        test_y=list(target)\n",
    "        while len(train_x) < train_size:\n",
    "            index = randrange(len(test_x))\n",
    "            train_x.append(test_x.pop(index))\n",
    "            train_y.append(test_y.pop(index))\n",
    "        return pd.DataFrame(train_x),train_y,pd.DataFrame(test_x),test_y\n",
    "        \n",
    "obj=DataSplit()\n",
    "train_x,train_y, test_x,test_y = obj.train_test_split(preprocess_data,target,0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualization:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def Histogram(self,data,title):\n",
    "        plt.hist(data)\n",
    "        plt.title(title,size=20)\n",
    "        plt.xlabel('TFIDF Values')\n",
    "        plt.show()\n",
    "    def build_word_cloud(self,words,back_color,palette,title) :\n",
    "        word_cloud = WordCloud(scale = 7,max_words = 1000,\n",
    "                               max_font_size = 100,background_color = back_color,\n",
    "                               random_state = 0,colormap = palette\n",
    "                              ).generate(\" \".join(words))\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.imshow(word_cloud,interpolation = \"bilinear\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(title,size=20)\n",
    "        plt.show()\n",
    "\n",
    "visual=Visualization()\n",
    "visual.Histogram(data,'Histogram of our pre-process Data')\n",
    "visual.build_word_cloud(doc,\"black\",\"rainbow\",\"word in our document\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "global DecisionTreeClassifier\n",
    "global SVC\n",
    "global KMeans\n",
    "\n",
    "class Predict: \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def Train(self,Catergory,number,train_x,train_y):\n",
    "        global cat\n",
    "        cat=Catergory\n",
    "        if Catergory=='a':\n",
    "            def Classification():\n",
    "                if number==1:\n",
    "                    def DecisionTree():\n",
    "                        Model=DecisionTreeClassifier()\n",
    "                        fitting=Model.fit(train_x,train_y)   \n",
    "                        return fitting\n",
    "                    return DecisionTree()\n",
    "                elif number==2:\n",
    "                    def SVM():\n",
    "                        Model=SVC()\n",
    "                        fitting=Model.fit(train_x,train_y)  \n",
    "                        return fitting\n",
    "                    return SVM()\n",
    "                else:\n",
    "                    warning=\"please Enter second valid argument 1 For Decision Tree, 2 For SVM but you enter \"+str(number)+\" Thank you\"\n",
    "                    return warning\n",
    "            return Classification()\n",
    "        elif Catergory=='b':\n",
    "            def Clustering():\n",
    "                    if number==1:\n",
    "                        def KmeanClustering():\n",
    "                            model=KMeans(2)\n",
    "                            fitting=model.fit(test_x)\n",
    "                            return fitting\n",
    "                        return KmeanClustering()        \n",
    "                    else:\n",
    "                            return \"Please Enter Valid number you Enter \"+str(number)+\" Thank you\"\n",
    "            return Clustering()\n",
    "        else:\n",
    "            return \"your First Argument Doesnot match with function you enter \"+Catergory+\" but you need to pass a  for classification and b for Clustering thank you!!! \"\n",
    "    def Predict(self,data):\n",
    "        result=fit.predict(data)\n",
    "        return result\n",
    "        \n",
    "        \n",
    "model=Predict()\n",
    "try:\n",
    "    fit=model.Train('a',1,train_x,train_y)\n",
    "    print(fit)\n",
    "    result=model.Predict(test_x)\n",
    "    print('predict of our data is :',result)\n",
    "except:\n",
    "    result=None\n",
    "    print(\"for prediction you need to solve above problem\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cat=='a':\n",
    "    class ModelEvaluate:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "        def perf_measure(self,y_actual, y_pred):\n",
    "            global TP,FP,TN,FN\n",
    "            TP = 0\n",
    "            FP = 0\n",
    "            TN = 0\n",
    "            FN = 0\n",
    "\n",
    "            for i in range(len(y_pred)): \n",
    "                if y_actual[i]==y_pred[i]:\n",
    "                    TP += 1\n",
    "                if y_pred[i]==1 and y_actual[i]!=y_pred[i]:\n",
    "                    FP += 1\n",
    "                if y_actual[i]==y_pred[i]==0:\n",
    "                    TN += 1\n",
    "                if y_pred[i]==0 and y_actual[i]!=y_pred[i]:\n",
    "                    FN += 1\n",
    "\n",
    "            return TP, FP, TN, FN\n",
    "\n",
    "        def Accuracy(self):\n",
    "            acc=(TP+TN)/(TP+FP+TN+FN)\n",
    "            return \"The Accuracy of Model Is \"+ str(acc)\n",
    "        def Precision(self):\n",
    "            global pre\n",
    "            pre=TP/(TP+FP)\n",
    "            return \"The Precision of Model Is \"+str(pre)\n",
    "        def Recall(self):\n",
    "            global rec\n",
    "            rec=TP/(TP+FN)\n",
    "            return \"The Recall of Model Is \"+ str(rec)\n",
    "        def F1score(self):\n",
    "            f1s=2*((pre*rec)/(pre+rec))\n",
    "            return 'The F1score of Model Is '+str(f1s)\n",
    "        \n",
    "    \n",
    "    \n",
    "    evaluate=ModelEvaluate()\n",
    "    evaluate.perf_measure(test_y,result)\n",
    "    print(evaluate.Accuracy())\n",
    "    print(evaluate.Precision())\n",
    "    print(evaluate.Recall())\n",
    "    print(evaluate.F1score())\n",
    "else:\n",
    "    print(\"we only evaluate Classification model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldValidation:\n",
    "    def cross_validation_split(self,dataset,target,folds=2):\n",
    "        dataset_split = []\n",
    "        target_split=[]\n",
    "        dataset_copy = list(dataset)\n",
    "        target_copy=list(target)\n",
    "        fold_size = int(len(dataset) / folds)\n",
    "        for i in range(folds):\n",
    "            fold1 = list()\n",
    "            fold2=list()\n",
    "            while len(fold1) < fold_size:\n",
    "                index = randrange(len(dataset_copy))\n",
    "                fold1.append(dataset_copy.pop(index))\n",
    "                fold2.append(target_copy.pop(index))\n",
    "            dataset_split.append(fold1)\n",
    "            target_split.append(fold2)\n",
    "        return dataset_split,target_split\n",
    "validation=KFoldValidation()\n",
    "a,b=validation.cross_validation_split(preprocess_data,target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Train('a',1,pd.DataFrame(a[0]),b[0])\n",
    "Result=model.Predict(pd.DataFrame(a[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=Result==test_y\n",
    "lst=[]\n",
    "for i in a:\n",
    "    if i==True:\n",
    "        lst.append(i)\n",
    "\n",
    "a=len(lst)\n",
    "b=len(Result)\n",
    "acc=(a/b)*100\n",
    "print('accuracy of our model is :',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Demo:\n",
    "    def Rabindra(self,a,n):\n",
    "        if a=='a':\n",
    "            def Sudhan():\n",
    "                if n==1:\n",
    "                    def Ke():\n",
    "                        return \"ke\"\n",
    "                    return Ke()\n",
    "                else:\n",
    "                    return \"xaina\"\n",
    "            return Sudhan()\n",
    "        else:\n",
    "            def Pitu():\n",
    "                return \"world\"\n",
    "            return Pitu()\n",
    "obj=Demo()\n",
    "obj.Rabindra('a',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[1,2,3,4,5]\n",
    "abc=[1,3,4]\n",
    "su=[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
